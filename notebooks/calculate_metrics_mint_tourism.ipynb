{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0931227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "stdout = sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b36b3352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tsaugmentation as tsag\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3cbd5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout = stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ba98ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def mase(n,seas,h,y,f):\n",
    "    return np.mean(((n-seas)/h\n",
    "            * (np.sum(np.abs(y[n:n+h,:] - f), axis=0)\n",
    "               / np.sum(np.abs(y[seas:n, :] - y[:n-seas, :]), axis=0))))\n",
    "\n",
    "def calculate_metrics(pred_samples,\n",
    "                      groups):\n",
    "\n",
    "    pred_s0 = pred_samples.shape[0]\n",
    "    pred_s1 = pred_samples.shape[1]\n",
    "    pred_s2 = pred_samples.shape[2]\n",
    "\n",
    "    pred_samples = pred_samples.reshape(pred_s0, pred_s1*pred_s2, order='F')\n",
    "\n",
    "    seasonality = groups['seasonality']\n",
    "    h = groups['h']\n",
    "    \n",
    "    n = groups['predict']['n']\n",
    "    s = groups['predict']['s']\n",
    "    y_f = groups['predict']['data'].reshape(s, n).T\n",
    "    y_all_g = {}\n",
    "    f_all_g = {}\n",
    "    \n",
    "    mase_ = {}\n",
    "    rmse_ = {}\n",
    "    \n",
    "    # Bottom\n",
    "    y_all_g['bottom'] = y_f\n",
    "    f_all_g['bottom'] = np.mean(pred_samples, axis=0).reshape(s, n).T[n-h:n,:]\n",
    "    \n",
    "    mase_['bottom'] = np.round(mase(n=n-h, \n",
    "                                     seas=seasonality, \n",
    "                                     h=h, \n",
    "                                     y=y_f, \n",
    "                                     f=np.mean(pred_samples, axis=0).reshape(s, n).T[n-h:n,:]),3)\n",
    "    rmse_['bottom'] = np.round(mean_squared_error(y_f[n-h:n,:], np.mean(pred_samples, axis=0).reshape(s, n).T[n-h:n,:], squared=False), 3)\n",
    "\n",
    "    # Total\n",
    "    y_all_g['total'] = np.sum(y_f, axis=1).reshape(-1,1)\n",
    "    f_all_g['total'] = np.sum(np.mean(pred_samples, axis=0).reshape(s, n).T[n-h:n,:], axis=1).reshape(-1,1)\n",
    "    \n",
    "    mase_['total'] = np.round(mase(n=n-h, \n",
    "                                     seas=seasonality, \n",
    "                                     h=h, \n",
    "                                     y=np.sum(y_f, axis=1).reshape(-1,1), \n",
    "                                     f=np.sum(np.mean(pred_samples, axis=0).reshape(s, n).T[n-h:n,:], axis=1).reshape(-1,1))\n",
    "                            ,3)\n",
    "    rmse_['total'] = np.round(mean_squared_error(np.sum(y_f, axis=1).reshape(-1,1)[n-h:n,:], \n",
    "                                             np.sum(np.mean(pred_samples, axis=0).reshape(s, n).T[n-h:n,:],axis=1).reshape(-1,1), \n",
    "                                             squared=False), 3)\n",
    "\n",
    "    # Groups\n",
    "    idx_dict_new = {}\n",
    "    for group in list(groups['predict']['groups_names'].keys()):\n",
    "        y_g = np.zeros((groups['predict']['n'], groups['predict']['groups_names'][group].shape[0]))\n",
    "        f_g = np.zeros((h, groups['predict']['groups_names'][group].shape[0]))\n",
    "\n",
    "        for idx, name in enumerate(groups['predict']['groups_names'][group]):               \n",
    "\n",
    "            g_n = groups['predict']['groups_n'][group]\n",
    "\n",
    "            idx_dict_new[name] = np.where(groups['predict']['groups_idx'][group]==idx,1,0)\n",
    "\n",
    "            y_g[:,idx] = np.sum(idx_dict_new[name]*y_f, axis=1)\n",
    "            f_g[:,idx] = np.sum(idx_dict_new[name]*np.mean(pred_samples, axis=0).reshape(s, n).T, axis=1)[n-h:n]\n",
    "\n",
    "        y_all_g[group] = np.sum(y_g, axis=1).reshape(-1,1)\n",
    "        f_all_g[group] = np.sum(f_g, axis=1).reshape(-1,1)\n",
    "\n",
    "        mase_[group] = np.round(mase(n=n-h, \n",
    "                                     seas=seasonality, \n",
    "                                     h=h, \n",
    "                                     y=y_g, \n",
    "                                     f=f_g)\n",
    "                                ,3)\n",
    "\n",
    "        rmse_[group] = np.round(mean_squared_error(y_g[n-h:n,:], f_g, squared=False), 3)\n",
    "\n",
    "    # All\n",
    "    y_all = np.concatenate([y_all_g[x] for x in y_all_g], 1)\n",
    "    f_all = np.concatenate([f_all_g[x] for x in f_all_g], 1)\n",
    "\n",
    "    mase_['all'] = np.round(mase(n=n-h, \n",
    "                         seas=seasonality, \n",
    "                         h=h, \n",
    "                         y=y_all, \n",
    "                         f=f_all),3)\n",
    "    rmse_['all'] = np.round(mean_squared_error(y_all[n-h:n,:], f_all, squared=False), 3)\n",
    "    \n",
    "    results = {}\n",
    "    results['mase'] = mase_\n",
    "    results['rmse'] = rmse_\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8315d746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of groups: 4\n",
      "\tstate: 7\n",
      "\tzone: 27\n",
      "\tregion: 76\n",
      "\tpurpose: 4\n",
      "Total number of series: 304\n",
      "Number of points per series for train: 204\n",
      "Total number of points: 228\n",
      "Seasonality: 12\n",
      "Forecast horizon: 24\n"
     ]
    }
   ],
   "source": [
    "dataset = tsag.preprocessing.PreprocessDatasets('tourism')\n",
    "groups = dataset.apply_preprocess()\n",
    "pred_mint = pd.read_csv('results_tourism_hts.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "030fc36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_mint(pred_mint, groups):\n",
    "    sort_groups=[]\n",
    "    groups_names = pred_mint.columns[:-3]\n",
    "    for group in groups_names:\n",
    "        pred_mint = pred_mint.loc[(pred_mint[group]!='<aggregated>')]\n",
    "        sort_group = pd.unique(groups['train']['groups_names'][group.lower()][groups['train']['groups_idx'][group.lower()]])\n",
    "        pred_mint[group] = pred_mint[group].astype(\"category\")\n",
    "        pred_mint[group].cat.set_categories(sort_group, inplace=True)\n",
    "\n",
    "    pred_mint = pred_mint.sort_values([k.title() for k in groups['train']['groups_names']])\n",
    "\n",
    "    pred_mint = pred_mint.reset_index().drop('index', axis=1)\n",
    "    \n",
    "    for group in groups_names:\n",
    "        # Assert order is correct between original dataset and predictions\n",
    "        np.testing.assert_array_equal(pd.unique(pred_mint[group]), pd.unique(groups['train']['groups_names'][group.lower()][groups['train']['groups_idx'][group.lower()]]))                           \n",
    "\n",
    "    h = groups['h']\n",
    "    s = groups['train']['s']\n",
    "    n = groups['train']['n']\n",
    "\n",
    "    pred = pred_mint['.mean'].to_numpy().reshape(s, h).T\n",
    "    pred_complete = np.concatenate((np.zeros((n, s)), pred), axis=0)[np.newaxis,:,:]\n",
    "    return pred_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9cb204d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_complete = calculate_metrics_mint(pred_mint, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "102582e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mase': {'bottom': 0.821,\n",
       "  'total': 1.368,\n",
       "  'state': 1.012,\n",
       "  'zone': 0.893,\n",
       "  'region': 0.805,\n",
       "  'purpose': 1.005,\n",
       "  'all': 0.83},\n",
       " 'rmse': {'bottom': 49.751,\n",
       "  'total': 2965.305,\n",
       "  'state': 618.056,\n",
       "  'zone': 239.419,\n",
       "  'region': 115.224,\n",
       "  'purpose': 903.6,\n",
       "  'all': 96.928}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(pred_complete, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a980af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
