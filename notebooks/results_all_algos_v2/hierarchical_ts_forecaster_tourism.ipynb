{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0d90230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mach2ne/anaconda3/envs/gpytorch/lib/python3.9/site-packages/gluonts/json.py:45: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gpforecaster as gpf\n",
    "import htsmodels as hts\n",
    "import tsaugmentation as tsag\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1d78307",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'tourism'\n",
    "dataset = tsag.preprocessing.PreprocessDatasets(dataset_name)\n",
    "groups = dataset.apply_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e5690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store original results\n",
    "\n",
    "for transf in ['jitter', 'time_warp', 'magnitude_warp', 'scaling']:\n",
    "    algorithm = 'gpf'\n",
    "    gpf_model = gpf.model.GPF(f'{dataset_name}_{algorithm}_{transf}_orig_s0', groups)\n",
    "    model, like = gpf_model.train()\n",
    "    mean, lower, upper = gpf_model.predict(model, like)\n",
    "    res = gpf_model.metrics(mean)\n",
    "    gpf_model.store_metrics(res)\n",
    "\n",
    "    algorithm = 'mint'\n",
    "    mint = hts.models.MinT(dataset=f'{dataset_name}_{algorithm}_{transf}_orig_s0', \n",
    "                           groups=groups, \n",
    "                           aggregate_key = '(State / Zone / Region) * Purpose')\n",
    "    forecasts = mint.train()\n",
    "    results = mint.results(forecasts)\n",
    "    res = mint.metrics(results)\n",
    "    mint.store_metrics(res)\n",
    "\n",
    "    algorithm = 'deepar'\n",
    "    deepar = hts.models.DeepAR(dataset=f'{dataset_name}_{algorithm}_{transf}_orig_s0', groups=groups)\n",
    "    model = deepar.train()\n",
    "    forecasts = deepar.predict(model)\n",
    "    results = deepar.results(forecasts)\n",
    "    res = deepar.metrics(results)\n",
    "    deepar.store_metrics(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d57a06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tsag.transformations.CreateTransformedVersions(dataset_name)\n",
    "data.parameters = {\"jitter\": 1.2,\n",
    "                   \"scaling\": 0.2,\n",
    "                   \"magnitude_warp\": 0.1,\n",
    "                   \"time_warp\": 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372a12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.create_new_version_single_transf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0505ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = tsag.visualization.Visualizer(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7379262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'gpf'\n",
    "for k in ['jitter', 'scaling', 'magnitude_warp', 'time_warp']:\n",
    "    vis._read_files(f'single_transf_{k}')\n",
    "    for i in range(6):\n",
    "        for j in range(10):\n",
    "            groups['train']['data'] = vis.y_new[i, j]\n",
    "            gpf_model = gpf.model.GPF(f'{dataset_name}_{algorithm}_{k}_v{i}_s{j}', groups)\n",
    "            model, like = gpf_model.train()\n",
    "            mean, lower, upper = gpf_model.predict(model, like)\n",
    "            res = gpf_model.metrics(mean)\n",
    "            gpf_model.store_metrics(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ff992",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'mint'\n",
    "for k in ['jitter', 'scaling', 'magnitude_warp', 'time_warp']:\n",
    "    vis._read_files(f'single_transf_{k}')\n",
    "    for i in range(6):\n",
    "        for j in range(10):\n",
    "            groups['train']['data'] = vis.y_new[i, j]\n",
    "            mint = hts.models.MinT(dataset=f'{dataset_name}_{algorithm}_{k}_v{i}_s{j}', \n",
    "                                   groups=groups,\n",
    "                                   aggregate_key = '(State / Zone / Region) * Purpose')\n",
    "            forecasts = mint.train()\n",
    "            results = mint.results(forecasts)\n",
    "            res = mint.metrics(results)\n",
    "            mint.store_metrics(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6cfe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'deepar'\n",
    "for k in ['jitter', 'scaling', 'magnitude_warp', 'time_warp']:\n",
    "    vis._read_files(f'single_transf_{k}')\n",
    "    for i in range(6):\n",
    "        for j in range(10):\n",
    "            groups['train']['data'] = vis.y_new[i, j]\n",
    "            deepar = hts.models.DeepAR(dataset=f'{dataset_name}_{algorithm}_{k}_v{i}_s{j}', groups=groups)\n",
    "            model = deepar.train()\n",
    "            forecasts = deepar.predict(model)\n",
    "            results = deepar.results(forecasts)\n",
    "            res = deepar.metrics(results)\n",
    "            deepar.store_metrics(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64325262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
