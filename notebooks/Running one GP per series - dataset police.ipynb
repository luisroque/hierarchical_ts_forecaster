{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "\n",
    "import os, sys\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: sys.path.append(dir1)\n",
    "from libs.model import HGPforecaster\n",
    "from libs.metrics import calculate_metrics, metrics_to_table\n",
    "from libs.pre_processing import generate_groups_data\n",
    "from libs.visual_analysis import visualize_fit, visualize_predict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "az.style.use('arviz-darkgrid')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "police = pd.read_excel('../data/NIBRSPublicView.Jan1-Nov30-2020.xlsx')\n",
    "\n",
    "police = police.drop(['Occurrence\\nHour', 'StreetName', 'Suffix', 'NIBRSDescription', 'Premise'], axis=1)\n",
    "police.columns = ['Id','Date', 'Crime', 'Count', 'Beat', 'Block', 'Street', 'City', 'ZIP']\n",
    "police = police.drop(['Id'], axis=1)\n",
    "police = police.loc[police['City']=='HOUSTON']\n",
    "police = police.drop(['City'], axis=1)\n",
    "\n",
    "# I am not using Block since there are 11901 blocks in the data\n",
    "police = police.groupby(['Date', 'Crime', 'Beat', 'Street', 'ZIP']).sum().reset_index().set_index('Date')\n",
    "\n",
    "police_pivot = police.reset_index().pivot(index='Date',columns=['Crime', 'Beat', 'Street', 'ZIP'], values='Count')\n",
    "police_pivot = police_pivot.fillna(0)\n",
    "\n",
    "groups_input = {\n",
    "    'Crime': [0],\n",
    "    'Beat': [1],\n",
    "    'Street': [2],\n",
    "    'ZIP': [3]\n",
    "}\n",
    "\n",
    "groups = generate_groups_data(police_pivot, groups_input, seasonality=7, h=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(groups['train']['n']).reshape(-1,1)\n",
    "X_new = np.arange(groups['predict']['n']).reshape(-1,1)\n",
    "\n",
    "p_s_fit = []\n",
    "p_s_predict = []\n",
    "\n",
    "for i in range(groups['train']['s']):    \n",
    "    with pm.Model() as model:\n",
    "\n",
    "        period = pm.Gamma('period', 70, 10)\n",
    "\n",
    "\n",
    "        l_t = pm.Gamma('l_t', 5, 1)#, testval=1)\n",
    "        l_p = pm.Gamma('l_p', 2, 1)#, testval=1)\n",
    "        η_trend = pm.HalfNormal('η_trend',0.15)#, testval=0.1)\n",
    "        η_per = pm.HalfNormal('η_per',0.5)#, testval=0.5)\n",
    "        σ  = pm.HalfNormal(\"σ\",  sigma=0.01)#, testval=0.01)\n",
    "\n",
    "        a = pm.Normal('a', 0,5) \n",
    "        b = pm.Normal('b', mu=0, sd=0.1)#, testval=0.1)\n",
    "\n",
    "        mu_func = pm.gp.mean.Linear(intercept = a,\n",
    "                                   coeffs = b)\n",
    "\n",
    "\n",
    "        # cov function for the GP \n",
    "        cov = (η_trend**2 * pm.gp.cov.ExpQuad(input_dim=1, ls=l_t)\n",
    "                + η_per**2 * pm.gp.cov.Periodic(1, period=period, ls=l_p) \n",
    "                + pm.gp.cov.WhiteNoise(σ))\n",
    "\n",
    "        gp = pm.gp.Latent(mean_func=mu_func, cov_func=cov)\n",
    "        f = gp.prior('f', X=X, reparameterize=True)\n",
    "\n",
    "        y_pred = pm.Poisson('y_pred', mu=tt.exp(f), observed=groups['train']['data'].reshape(groups['train']['s'], groups['train']['n']).T[:,i])\n",
    "        mp = pm.find_MAP(maxeval=5000, progressbar = False)\n",
    "        \n",
    "        pred_samples_fit = pm.sample_posterior_predictive([mp], \n",
    "                                      vars=[y_pred], \n",
    "                                      samples=200,\n",
    "                                      progressbar=False)\n",
    "\n",
    "        f_n = gp.conditional('f_n', Xnew=X_new)\n",
    "\n",
    "        y_pred_new = pm.Poisson(\"y_pred_new\", \n",
    "                                mu=tt.exp(f_n), \n",
    "                                shape=X_new.shape[0])\n",
    "\n",
    "        pred_samples_predict = pm.sample_posterior_predictive([mp], \n",
    "                                                  vars=[y_pred_new], \n",
    "                                                  samples=200,\n",
    "                                                  progressbar = False)\n",
    "\n",
    "    print(str(i)+'/'+str(groups['train']['s']-1))\n",
    "    p_s_fit.append(pred_samples_fit['y_pred'])\n",
    "    p_s_predict.append(pred_samples_predict['y_pred_new'])\n",
    "\n",
    "p_s_fit = np.asarray(p_s_fit)\n",
    "p_s_predict = np.asarray(p_s_predict)\n",
    "p_s_fit = p_s_fit.transpose(1, 0, 2).reshape(200, groups['train']['n']*groups['train']['s'])\n",
    "p_s_predict = p_s_predict.transpose(1, 0, 2).reshape(200, groups['predict']['n']*groups['predict']['s'])\n",
    "p_s_fit_d = {}\n",
    "p_s_predict_d = {}\n",
    "p_s_fit_d['y_pred'] = p_s_fit\n",
    "p_s_predict_d['y_pred_new'] = p_s_predict\n",
    "\n",
    "visualize_fit(groups, p_s_fit_d, 8)\n",
    "\n",
    "visualize_predict(groups, p_s_predict_d, 8)\n",
    "\n",
    "results = calculate_metrics(p_s_predict_d, groups)\n",
    "metrics_to_table(groups, results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
